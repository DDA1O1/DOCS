---
title: Machine Learning
---

## Types of Machine Learning

Machine learning can be divided into three main categories based on how models learn from data.

### 1. Supervised Learning
Models learn from labeled data to make predictions.

#### How it Works
- Input: Data with known answers (labels)
- Process: Model learns patterns between features and labels
- Output: Predictions for new data

#### Types
1. **Classification** (Predicts categories)
```python
from sklearn.ensemble import RandomForestClassifier

# Disease Classification Example
class DiseaseClassifier:
    def __init__(self):
        self.model = RandomForestClassifier()
    
    def train(self, symptoms, diagnoses):
        """Train with patient symptoms and known diagnoses"""
        self.model.fit(symptoms, diagnoses)
    
    def predict(self, patient_symptoms):
        """Predict disease category"""
        return self.model.predict([patient_symptoms])[0]

# Example Usage
symptoms = [
    [1, 0, 1],  # Patient 1: [fever, cough, fatigue]
    [0, 1, 0],  # Patient 2
    [1, 1, 1]   # Patient 3
]
diagnoses = ['flu', 'cold', 'flu']

classifier = DiseaseClassifier()
classifier.train(symptoms, diagnoses)
new_patient = [1, 0, 1]
prediction = classifier.predict(new_patient)
```

2. **Regression** (Predicts numbers)
```python
from sklearn.linear_model import LinearRegression

# House Price Prediction
class PricePredictor:
    def __init__(self):
        self.model = LinearRegression()
    
    def train(self, features, prices):
        """Train with house features and known prices"""
        self.model.fit(features, prices)
    
    def predict(self, house_features):
        """Predict house price"""
        return self.model.predict([house_features])[0]

# Example Usage
features = [
    [1500, 3],  # [size, bedrooms]
    [2000, 4],
    [1200, 2]
]
prices = [300000, 450000, 250000]

predictor = PricePredictor()
predictor.train(features, prices)
new_house = [1800, 3]
price = predictor.predict(new_house)
```

### 2. Unsupervised Learning
Models find patterns in unlabeled data.

#### How it Works
- Input: Data without labels
- Process: Model discovers inherent patterns
- Output: Groups or structures in data

#### Types
1. **Clustering** (Groups similar items)
```python
from sklearn.cluster import KMeans

class CustomerSegmentation:
    def __init__(self, n_clusters=3):
        self.model = KMeans(n_clusters=n_clusters)
    
    def segment(self, customer_data):
        """Group customers by behavior"""
        return self.model.fit_predict(customer_data)

# Example Usage
customers = [
    [100, 20],  # [spending, visits]
    [500, 50],
    [50, 10]
]
segmentation = CustomerSegmentation()
segments = segmentation.segment(customers)
```

2. **Dimensionality Reduction** (Simplifies data)
```python
from sklearn.decomposition import PCA

class ImageCompressor:
    def __init__(self, n_components=2):
        self.model = PCA(n_components=n_components)
    
    def compress(self, images):
        """Reduce image dimensions"""
        return self.model.fit_transform(images)

# Example Usage
images = [
    [1, 2, 3, 4],  # Each row is a flattened image
    [2, 3, 4, 5],
    [3, 4, 5, 6]
]
compressor = ImageCompressor()
compressed = compressor.compress(images)
```

### 3. Reinforcement Learning
Models learn through trial and error with rewards.

#### How it Works
- Input: Environment state
- Process: Agent takes actions and receives rewards
- Output: Optimal action policy

```python
class GameAgent:
    def __init__(self, states, actions):
        self.q_table = {}  # State-action values
        
    def choose_action(self, state):
        """Choose best action for current state"""
        if state not in self.q_table:
            self.q_table[state] = [0] * len(self.actions)
        return np.argmax(self.q_table[state])
    
    def learn(self, state, action, reward, next_state):
        """Update knowledge based on reward"""
        old_value = self.q_table[state][action]
        next_max = np.max(self.q_table[next_state])
        self.q_table[state][action] = old_value + 0.1 * (reward + 0.9 * next_max - old_value)

# Example Usage
agent = GameAgent(states=['start', 'middle', 'end'], actions=['left', 'right'])
state = 'start'
action = agent.choose_action(state)
```

### Key Differences

1. **Supervised vs Unsupervised**
   - Supervised: Has correct answers to learn from
   - Unsupervised: Finds patterns without answers

2. **Supervised vs Reinforcement**
   - Supervised: Learns from static examples
   - Reinforcement: Learns from dynamic interaction

3. **Unsupervised vs Reinforcement**
   - Unsupervised: Finds structure in data
   - Reinforcement: Learns optimal behavior

### When to Use Each

1. **Use Supervised Learning When**
   - You have labeled data
   - Need specific predictions
   - Have clear input-output pairs

2. **Use Unsupervised Learning When**
   - Data isn't labeled
   - Want to discover patterns
   - Need to reduce data complexity

3. **Use Reinforcement Learning When**
   - Have interactive environment
   - Can define clear rewards
   - Need adaptive behavior

### Common Applications

1. **Supervised Learning**
   - Spam detection
   - Disease diagnosis
   - Price prediction
   - Image recognition

2. **Unsupervised Learning**
   - Customer segmentation
   - Anomaly detection
   - Feature extraction
   - Recommendation systems

3. **Reinforcement Learning**
   - Game playing
   - Robot navigation
   - Resource management
   - Trading strategies

> **Remember**: Choose the learning type based on your data availability and problem requirements. Each type has its strengths and ideal use cases.

### Supervised Learning

Supervised learning is a type of machine learning where models learn from labeled data to make predictions on new, unseen data.

### Key Concepts

1. **Input Data (X)**: Features or predictors
2. **Output Data (y)**: Labels or target values
3. **Training**: Model learns patterns from X â†’ y mapping
4. **Prediction**: Model predicts y for new X

### Types of Supervised Learning

#### 1. Classification
- Predicts categorical outputs
- Examples: Yes/No, Cat/Dog/Bird

```python
from sklearn.ensemble import RandomForestClassifier

# Email Spam Classification
class SpamClassifier:
    def __init__(self):
        self.model = RandomForestClassifier()
        
    def train(self, emails, labels):
        """
        Train spam classifier
        
        Args:
            emails: List of email features (word counts, etc.)
            labels: 1 for spam, 0 for not spam
        """
        self.model.fit(emails, labels)
    
    def predict(self, email):
        """Predict if email is spam"""
        prediction = self.model.predict([email])[0]
        return "Spam" if prediction == 1 else "Not Spam"

# Example Usage
features = [[1, 0, 2], [0, 0, 0], [3, 1, 4]]  # Word counts: [money, friend, buy]
labels = [1, 0, 1]  # 1=spam, 0=not spam

classifier = SpamClassifier()
classifier.train(features, labels)

new_email = [2, 0, 3]  # New email features
result = classifier.predict(new_email)
print(f"Email classified as: {result}")
```

#### 2. Regression
- Predicts continuous numerical values
- Examples: Price, Temperature, Age

```python
from sklearn.linear_model import LinearRegression
import numpy as np

class HousePricePredictor:
    def __init__(self):
        self.model = LinearRegression()
        
    def train(self, features, prices):
        """
        Train house price predictor
        
        Args:
            features: Array of [size, bedrooms, age]
            prices: Array of house prices
        """
        self.model.fit(features, prices)
    
    def predict(self, house):
        """Predict house price"""
        return self.model.predict([house])[0]

# Example Usage
features = [
    [1500, 3, 10],  # size, bedrooms, age
    [2000, 4, 5],
    [1200, 2, 15]
]
prices = [300000, 450000, 250000]

predictor = HousePricePredictor()
predictor.train(features, prices)

new_house = [1800, 3, 8]
price = predictor.predict(new_house)
print(f"Predicted price: ${price:,.2f}")
```

### Common Algorithms

1. **Linear Models**
   - Linear Regression
   - Logistic Regression
   - Use: Simple, interpretable predictions

2. **Tree-Based Models**
   - Decision Trees
   - Random Forests
   - Use: Complex patterns, non-linear relationships

3. **Neural Networks**
   - Deep Learning
   - Multi-layer Perceptron
   - Use: Image, text, complex patterns

### Real-World Applications

#### 1. Credit Card Fraud Detection
```python
class FraudDetector:
    def __init__(self):
        self.model = RandomForestClassifier()
        
    def train(self, transactions, fraud_labels):
        """
        Train fraud detector
        
        Args:
            transactions: Features [amount, time, location_code, etc.]
            fraud_labels: 1 for fraud, 0 for legitimate
        """
        self.model.fit(transactions, fraud_labels)
    
    def check_transaction(self, transaction):
        """Check if transaction is fraudulent"""
        risk_score = self.model.predict_proba([transaction])[0][1]
        return {
            'risk_score': risk_score,
            'flag_for_review': risk_score > 0.7
        }

# Example
detector = FraudDetector()
transaction = [1000, 3, 45]  # amount, time, location
result = detector.check_transaction(transaction)
print(f"Risk Score: {result['risk_score']:.2%}")
```

#### 2. Medical Diagnosis
```python
class DiseasePredictor:
    def __init__(self):
        self.model = RandomForestClassifier()
        
    def train(self, patient_data, diagnoses):
        """
        Train disease predictor
        
        Args:
            patient_data: Features [symptoms, age, history, etc.]
            diagnoses: Disease labels
        """
        self.model.fit(patient_data, diagnoses)
    
    def predict_risk(self, patient):
        """Predict disease risk"""
        probability = self.model.predict_proba([patient])[0][1]
        return {
            'risk_level': 'High' if probability > 0.7 else 'Low',
            'probability': probability
        }

# Example
symptoms = [1, 0, 1, 0]  # fever, cough, fatigue, pain
result = DiseasePredictor().predict_risk(symptoms)
print(f"Risk Level: {result['risk_level']}")
```

### Best Practices

1. **Data Quality**
   - Clean, representative data
   - Balanced classes
   - Proper feature scaling

2. **Model Selection**
   - Start simple
   - Use cross-validation
   - Consider interpretability needs

3. **Evaluation**
   - Use appropriate metrics
   - Test on unseen data
   - Monitor performance

### Common Challenges

1. **Overfitting**
   - Model learns noise in training data
   - Solution: Regularization, cross-validation

2. **Underfitting**
   - Model too simple for data
   - Solution: More features, complex model

3. **Data Issues**
   - Missing values
   - Imbalanced classes
   - Noisy labels

### Performance Metrics

#### Classification
```python
from sklearn.metrics import accuracy_score, precision_score, recall_score

def evaluate_classifier(y_true, y_pred):
    """Calculate classification metrics"""
    return {
        'accuracy': accuracy_score(y_true, y_pred),
        'precision': precision_score(y_true, y_pred),
        'recall': recall_score(y_true, y_pred)
    }
```

#### Regression
```python
from sklearn.metrics import mean_squared_error, r2_score

def evaluate_regression(y_true, y_pred):
    """Calculate regression metrics"""
    return {
        'mse': mean_squared_error(y_true, y_pred),
        'r2': r2_score(y_true, y_pred)
    }
```

### When to Use

1. **Classification**
   - Spam detection
   - Disease diagnosis
   - Customer churn prediction
   - Image recognition

2. **Regression**
   - Price prediction
   - Sales forecasting
   - Temperature estimation
   - Resource consumption

> **Remember**: Success in supervised learning depends heavily on data quality and proper model selection for your specific problem.
